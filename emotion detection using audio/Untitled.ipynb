{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb71b31-83b1-4f88-9bae-395816d67b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-robust-ft-swbd-300h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Emotion: happy\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install torch transformers librosa soundfile\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# Load pre-trained model and feature extractor\n",
    "model_name = \"facebook/wav2vec2-large-robust-ft-swbd-300h\"  # Example model, fine-tune for emotion detection\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Define emotion labels (example labels, adjust based on your dataset)\n",
    "emotion_labels = {\n",
    "    0: \"neutral\",\n",
    "    1: \"happy\",\n",
    "    2: \"sad\",\n",
    "    3: \"angry\",\n",
    "    4: \"fearful\",\n",
    "    5: \"disgust\",\n",
    "    6: \"surprised\"\n",
    "}\n",
    "\n",
    "# Load and preprocess audio file\n",
    "def preprocess_audio(file_path):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz\n",
    "    # Extract features\n",
    "    inputs = feature_extractor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    return inputs\n",
    "\n",
    "# Perform emotion detection\n",
    "def detect_emotion(file_path):\n",
    "    # Preprocess audio\n",
    "    inputs = preprocess_audio(file_path)\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    # Get predicted emotion\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    emotion = emotion_labels.get(predicted_class, \"unknown\")\n",
    "    return emotion\n",
    "\n",
    "# Test the function\n",
    "file_path = \"surprised.wav\"  # Replace with your audio file path\n",
    "emotion = detect_emotion(file_path)\n",
    "print(f\"Detected Emotion: {emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2eea1-1399-4d4a-be9d-3b7f346e1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained model and feature extractor\n",
    "model_name = \"facebook/wav2vec2-large-robust-ft-swbd-300h\"  # Example model, you can replace it with a suitable one\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = {\n",
    "    0: \"neutral\",\n",
    "    1: \"happy\",\n",
    "    2: \"sad\",\n",
    "    3: \"angry\",\n",
    "    4: \"fearful\",\n",
    "    5: \"disgust\",\n",
    "    6: \"surprised\"\n",
    "}\n",
    "\n",
    "# Load and preprocess audio file\n",
    "def preprocess_audio(file_path):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz\n",
    "    # Extract features\n",
    "    inputs = feature_extractor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    return inputs\n",
    "\n",
    "# Perform emotion detection\n",
    "def detect_emotion(file_path):\n",
    "    # Preprocess audio\n",
    "    inputs = preprocess_audio(file_path)\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    # Get predicted emotion\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    emotion = emotion_labels.get(predicted_class, \"unknown\")\n",
    "    return predicted_class, emotion\n",
    "\n",
    "# Define a simple dataset (file paths and ground truth labels)\n",
    "test_files = [\"surprised.wav\"]  # Replace with your audio files\n",
    "ground_truth = [6]  # Replace with actual labels corresponding to the audio files\n",
    "\n",
    "# Store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Perform emotion detection for each file in the test set\n",
    "for file in test_files:\n",
    "    predicted_class, _ = detect_emotion(file)\n",
    "    predicted_labels.append(predicted_class)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(ground_truth, predicted_labels)\n",
    "precision = precision_score(ground_truth, predicted_labels, average='weighted')\n",
    "recall = recall_score(ground_truth, predicted_labels, average='weighted')\n",
    "f1 = f1_score(ground_truth, predicted_labels, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Plot the metrics\n",
    "metrics = [accuracy, precision, recall, f1]\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics_names, metrics, color='skyblue')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Emotion Detection Performance Metrics')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1371eb-fa10-431a-a2cd-d12a28a74cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting torch==2.5.1 (from torchaudio)\n",
      "  Using cached torch-2.5.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchaudio) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
      "Using cached torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a288da94da5149eda885022d536dc0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SASAPU TARUN\\.cache\\huggingface\\hub\\models--audeering--wav2vec2-large-robust-12-ft-emotion-msp-dim. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b0c93ee3d74db28a385110caca0f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033ab290c43349d6a2c12d8ff2e41f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f033dd8e52b4be792f02265f5fc12e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/661M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     72\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msad.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your file\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m waveform, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[0;32m     75\u001b[0m plot_results(waveform, sr, probs)\n",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m, in \u001b[0;36manalyze_emotion\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Get probabilities\u001b[39;00m\n\u001b[0;32m     42\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:2357\u001b[0m, in \u001b[0;36mWav2Vec2ForSequenceClassification.forward\u001b[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   2354\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   2355\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum \u001b[38;5;28;01melse\u001b[39;00m output_hidden_states\n\u001b[1;32m-> 2357\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum:\n\u001b[0;32m   2366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[_HIDDEN_STATES_START_POSITION]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1822\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1817\u001b[0m hidden_states, extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projection(extract_features)\n\u001b[0;32m   1818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_hidden_states(\n\u001b[0;32m   1819\u001b[0m     hidden_states, mask_time_indices\u001b[38;5;241m=\u001b[39mmask_time_indices, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[0;32m   1820\u001b[0m )\n\u001b[1;32m-> 1822\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1830\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1126\u001b[0m, in \u001b[0;36mWav2Vec2EncoderStableLayerNorm.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1123\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m position_embeddings\n\u001b[0;32m   1124\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m-> 1126\u001b[0m synced_gpus \u001b[38;5;241m=\u001b[39m is_deepspeed_zero3_enabled() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_fsdp_managed_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\integrations\\fsdp.py:29\u001b[0m, in \u001b[0;36mis_fsdp_managed_module\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mfsdp\u001b[38;5;241m.\u001b[39mFullyShardedDataParallel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m     32\u001b[0m     module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_fsdp_managed_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flat_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     BackwardPrefetch,\n\u001b[0;32m      4\u001b[0m     CPUOffload,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     StateDictType,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackwardPrefetch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPUOffload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateDictType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:38\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     _FSDPDeviceHandle,\n\u001b[0;32m     33\u001b[0m     _named_parameters_with_duplicates,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     HandleTrainingState,\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     _alloc_storage,\n\u001b[0;32m     40\u001b[0m     _data_ptr_allocated,\n\u001b[0;32m     41\u001b[0m     _free_storage,\n\u001b[0;32m     42\u001b[0m     _p_assert,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_pg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeProcessGroup\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\utils.py)"
     ]
    }
   ],
   "source": [
    "!pip install transformers torchaudio librosa pandas numpy matplotlib seaborn\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# Load publicly available model\n",
    "model_name = \"audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Emotion labels for this specific model\n",
    "emotion_labels = {\n",
    "    0: \"Anger\",\n",
    "    1: \"Sadness\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Happiness\",\n",
    "    4: \"Fear\"\n",
    "}\n",
    "\n",
    "def analyze_emotion(audio_path):\n",
    "    # Load and resample audio\n",
    "    waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # Preprocess\n",
    "    inputs = processor(\n",
    "        waveform,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()[0]\n",
    "    return probs\n",
    "\n",
    "def plot_results(waveform, sr, probabilities):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Waveform\n",
    "    plt.subplot(1, 3, 1)\n",
    "    librosa.display.waveshow(waveform, sr=sr)\n",
    "    plt.title(\"Audio Waveform\")\n",
    "    \n",
    "    # Spectrogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    X = librosa.stft(waveform)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(\"Spectrogram\")\n",
    "    \n",
    "    # Emotion probabilities\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.barplot(x=list(emotion_labels.values()), y=probabilities, palette=\"viridis\")\n",
    "    plt.title(\"Emotion Probabilities\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Confidence\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "audio_path = \"sad.wav\"  # Replace with your file\n",
    "probs = analyze_emotion(audio_path)\n",
    "waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "plot_results(waveform, sr, probs)\n",
    "\n",
    "# Print results\n",
    "print(\"Emotion Predictions:\")\n",
    "for emotion, prob in zip(emotion_labels.values(), probs):\n",
    "    print(f\"{emotion}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e7dec2-c972-4579-afec-11a8d19a2290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/204.2 MB 8.4 MB/s eta 0:00:25\n",
      "    --------------------------------------- 2.9/204.2 MB 7.6 MB/s eta 0:00:27\n",
      "    --------------------------------------- 4.2/204.2 MB 7.6 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 5.5/204.2 MB 7.3 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 6.6/204.2 MB 6.9 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 7.3/204.2 MB 6.2 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 8.4/204.2 MB 6.0 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 9.7/204.2 MB 5.9 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 10.7/204.2 MB 5.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 12.1/204.2 MB 5.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 13.6/204.2 MB 6.0 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 15.2/204.2 MB 6.1 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 16.3/204.2 MB 6.1 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 17.3/204.2 MB 6.1 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 18.6/204.2 MB 6.0 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 19.7/204.2 MB 6.0 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 21.0/204.2 MB 6.0 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 22.5/204.2 MB 6.1 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 23.6/204.2 MB 6.1 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 24.9/204.2 MB 6.1 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 26.2/204.2 MB 6.1 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 27.5/204.2 MB 6.1 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 29.1/204.2 MB 6.2 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 30.7/204.2 MB 6.2 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 32.2/204.2 MB 6.3 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 33.8/204.2 MB 6.3 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 35.1/204.2 MB 6.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 36.7/204.2 MB 6.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 38.5/204.2 MB 6.4 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 39.8/204.2 MB 6.4 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 41.4/204.2 MB 6.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 43.0/204.2 MB 6.5 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 44.3/204.2 MB 6.5 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 46.1/204.2 MB 6.6 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 47.7/204.2 MB 6.6 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 49.3/204.2 MB 6.6 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 50.9/204.2 MB 6.6 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 52.4/204.2 MB 6.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 54.0/204.2 MB 6.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 55.6/204.2 MB 6.7 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 57.1/204.2 MB 6.7 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 58.7/204.2 MB 6.7 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 60.3/204.2 MB 6.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 61.9/204.2 MB 6.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 63.4/204.2 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 65.0/204.2 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 66.6/204.2 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 68.2/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 69.7/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 71.3/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 72.6/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 73.9/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 75.2/204.2 MB 6.8 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 76.3/204.2 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 77.6/204.2 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 78.9/204.2 MB 6.7 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 80.5/204.2 MB 6.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 81.8/204.2 MB 6.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 83.6/204.2 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 85.2/204.2 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 86.5/204.2 MB 6.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 87.8/204.2 MB 6.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 89.4/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 91.0/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 92.5/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 94.1/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 95.4/204.2 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 97.3/204.2 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 98.6/204.2 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 100.4/204.2 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 101.7/204.2 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 103.5/204.2 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 105.1/204.2 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 106.7/204.2 MB 6.9 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 108.3/204.2 MB 6.9 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 109.8/204.2 MB 6.9 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 111.7/204.2 MB 6.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 113.2/204.2 MB 6.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 114.8/204.2 MB 6.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 116.4/204.2 MB 6.9 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 118.0/204.2 MB 6.9 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 119.5/204.2 MB 6.9 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 121.1/204.2 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 122.7/204.2 MB 7.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 124.5/204.2 MB 7.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 126.1/204.2 MB 7.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 127.7/204.2 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 129.2/204.2 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 131.1/204.2 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 132.6/204.2 MB 7.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 134.2/204.2 MB 7.0 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 135.8/204.2 MB 7.0 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 137.4/204.2 MB 7.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 138.9/204.2 MB 7.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 140.5/204.2 MB 7.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 142.3/204.2 MB 7.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 143.7/204.2 MB 7.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 145.5/204.2 MB 7.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 147.1/204.2 MB 7.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 148.6/204.2 MB 7.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 150.2/204.2 MB 7.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 151.8/204.2 MB 7.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 153.4/204.2 MB 7.1 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 155.2/204.2 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 156.8/204.2 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 158.3/204.2 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 159.9/204.2 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 161.5/204.2 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 163.1/204.2 MB 7.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.6/204.2 MB 7.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 166.2/204.2 MB 7.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 167.8/204.2 MB 7.1 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 169.3/204.2 MB 7.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 171.2/204.2 MB 7.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 172.8/204.2 MB 7.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 174.3/204.2 MB 7.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 175.9/204.2 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 177.5/204.2 MB 7.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.0/204.2 MB 7.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.6/204.2 MB 7.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 182.2/204.2 MB 7.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 183.8/204.2 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.3/204.2 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.9/204.2 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 188.5/204.2 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 189.8/204.2 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.4/204.2 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 192.9/204.2 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.5/204.2 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.3/204.2 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.5/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.1/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.6/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 204.2/204.2 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.6/2.4 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.0 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1\n",
      "    Uninstalling torchaudio-2.5.1:\n",
      "      Successfully uninstalled torchaudio-2.5.1\n",
      "Successfully installed torch-2.6.0 torchaudio-2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchaudio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dfa136-bffe-40f5-a9d8-6d42b221b2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchaudio) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0->torchaudio) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0->torchaudio) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasapu tarun\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     72\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msad.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your file\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m waveform, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[0;32m     75\u001b[0m plot_results(waveform, sr, probs)\n",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m, in \u001b[0;36manalyze_emotion\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Get probabilities\u001b[39;00m\n\u001b[0;32m     42\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:2357\u001b[0m, in \u001b[0;36mWav2Vec2ForSequenceClassification.forward\u001b[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   2354\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   2355\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum \u001b[38;5;28;01melse\u001b[39;00m output_hidden_states\n\u001b[1;32m-> 2357\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum:\n\u001b[0;32m   2366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[_HIDDEN_STATES_START_POSITION]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1822\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1817\u001b[0m hidden_states, extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projection(extract_features)\n\u001b[0;32m   1818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_hidden_states(\n\u001b[0;32m   1819\u001b[0m     hidden_states, mask_time_indices\u001b[38;5;241m=\u001b[39mmask_time_indices, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[0;32m   1820\u001b[0m )\n\u001b[1;32m-> 1822\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1830\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_warn_non_full_backward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, result, grad_fn):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1508\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m-> 1511\u001b[0m         ):\n\u001b[0;32m   1512\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m             )\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(r, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m   1511\u001b[0m     ):\n\u001b[0;32m   1512\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing non-full backward hooks on a Module that does not return a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle Tensor or a tuple of Tensors is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[1;32m-> 1520\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1126\u001b[0m, in \u001b[0;36mWav2Vec2EncoderStableLayerNorm.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1123\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m position_embeddings\n\u001b[0;32m   1124\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m-> 1126\u001b[0m synced_gpus \u001b[38;5;241m=\u001b[39m is_deepspeed_zero3_enabled() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_fsdp_managed_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\integrations\\fsdp.py:29\u001b[0m, in \u001b[0;36mis_fsdp_managed_module\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mfsdp\u001b[38;5;241m.\u001b[39mFullyShardedDataParallel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m     32\u001b[0m     module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_fsdp_managed_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flat_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fully_shard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     CPUOffloadPolicy,\n\u001b[0;32m      4\u001b[0m     FSDPModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     UnshardHandle,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     BackwardPrefetch,\n\u001b[0;32m     13\u001b[0m     CPUOffload,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     StateDictType,\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:38\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     _FSDPDeviceHandle,\n\u001b[0;32m     33\u001b[0m     _named_parameters_with_duplicates,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     HandleTrainingState,\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     _alloc_storage,\n\u001b[0;32m     40\u001b[0m     _data_ptr_allocated,\n\u001b[0;32m     41\u001b[0m     _free_storage,\n\u001b[0;32m     42\u001b[0m     _p_assert,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_pg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeProcessGroup\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_data_ptr_allocated' from 'torch.distributed.utils' (C:\\Users\\SASAPU TARUN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributed\\utils.py)"
     ]
    }
   ],
   "source": [
    "!pip install transformers torchaudio librosa pandas numpy matplotlib seaborn\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# Load publicly available model\n",
    "model_name = \"audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Emotion labels for this specific model\n",
    "emotion_labels = {\n",
    "    0: \"Anger\",\n",
    "    1: \"Sadness\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Happiness\",\n",
    "    4: \"Fear\"\n",
    "}\n",
    "\n",
    "def analyze_emotion(audio_path):\n",
    "    # Load and resample audio\n",
    "    waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # Preprocess\n",
    "    inputs = processor(\n",
    "        waveform,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()[0]\n",
    "    return probs\n",
    "\n",
    "def plot_results(waveform, sr, probabilities):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Waveform\n",
    "    plt.subplot(1, 3, 1)\n",
    "    librosa.display.waveshow(waveform, sr=sr)\n",
    "    plt.title(\"Audio Waveform\")\n",
    "    \n",
    "    # Spectrogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    X = librosa.stft(waveform)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(\"Spectrogram\")\n",
    "    \n",
    "    # Emotion probabilities\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.barplot(x=list(emotion_labels.values()), y=probabilities, palette=\"viridis\")\n",
    "    plt.title(\"Emotion Probabilities\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Confidence\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "audio_path = \"sad.wav\"  # Replace with your file\n",
    "probs = analyze_emotion(audio_path)\n",
    "waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "plot_results(waveform, sr, probs)\n",
    "\n",
    "# Print results\n",
    "print(\"Emotion Predictions:\")\n",
    "for emotion, prob in zip(emotion_labels.values(), probs):\n",
    "    print(f\"{emotion}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5e995-d996-41c8-9dfa-865f2d80c63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
